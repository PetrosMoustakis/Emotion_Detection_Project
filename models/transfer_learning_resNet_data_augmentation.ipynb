{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T17:42:11.837063Z",
     "start_time": "2025-07-25T17:42:10.488739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install keras-cv"
   ],
   "id": "a96c1ecb37c143c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-cv in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-cv) (25.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-cv) (2.3.0)\n",
      "Requirement already satisfied: regex in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-cv) (2024.11.6)\n",
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-cv) (4.9.9)\n",
      "Requirement already satisfied: keras-core in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-cv) (0.1.7)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-cv) (0.3.12)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from kagglehub->keras-cv) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from kagglehub->keras-cv) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from kagglehub->keras-cv) (4.67.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-core->keras-cv) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-core->keras-cv) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-core->keras-cv) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-core->keras-cv) (3.13.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from keras-core->keras-cv) (0.1.9)\n",
      "Requirement already satisfied: attrs>=18.2.0 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from dm-tree->keras-core->keras-cv) (25.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from dm-tree->keras-core->keras-cv) (1.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from requests->kagglehub->keras-cv) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from requests->kagglehub->keras-cv) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from requests->kagglehub->keras-cv) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from requests->kagglehub->keras-cv) (2025.4.26)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from rich->keras-core->keras-cv) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from rich->keras-core->keras-cv) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv) (0.1.2)\n",
      "Requirement already satisfied: etils>=1.9.1 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (1.13.0)\n",
      "Requirement already satisfied: immutabledict in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (4.2.1)\n",
      "Requirement already satisfied: promise in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (5.29.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (7.0.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (21.0.0)\n",
      "Requirement already satisfied: simple_parsing in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (0.1.7)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (1.17.2)\n",
      "Requirement already satisfied: termcolor in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (3.1.0)\n",
      "Requirement already satisfied: toml in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-datasets->keras-cv) (0.10.2)\n",
      "Requirement already satisfied: einops in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (0.8.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (2025.7.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (6.5.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (4.14.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (3.23.0)\n",
      "Requirement already satisfied: six in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from promise->tensorflow-datasets->keras-cv) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from simple_parsing->tensorflow-datasets->keras-cv) (0.17.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv) (1.70.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\petro\\pycharmprojects\\emotion_detector_project\\.venv\\lib\\site-packages (from tqdm->kagglehub->keras-cv) (0.4.6)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. IMPORT LIBRARIES\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from src.config import train_dir, test_dir, val_dir\n",
    "print(\"✅ Libraries installed and imported.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "transfer_img_height = 224\n",
    "transfer_img_width = 224\n",
    "transfer_color_mode = 'rgb'\n",
    "batch_size = 32"
   ],
   "id": "f8f7780d12bdf172"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode = 'categorical',\n",
    "    image_size = (transfer_img_height, transfer_img_width),\n",
    "    color_mode = transfer_color_mode,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels='inferred',\n",
    "    label_mode = 'categorical',\n",
    "    image_size = (transfer_img_height, transfer_img_width),\n",
    "    color_mode = transfer_color_mode,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode = 'categorical',\n",
    "    image_size = (transfer_img_height, transfer_img_width),\n",
    "    color_mode = transfer_color_mode,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")"
   ],
   "id": "c7d59ac939fd39e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from keras_cv.layers import RandomBrightness, RandomContrast, RandomSaturation, RandomHue, RandomFlip, RandomRotation, RandomZoom\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "    RandomContrast(value_range=(0, 255), factor=0.2),\n",
    "    RandomZoom(0.05),\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.05),\n",
    "], name=\"keras_cv_augmentation\")\n",
    "\n",
    "train_ds_augmented = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)"
   ],
   "id": "5c124ae88668fe66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "preprocess_input_resnet50 = tf.keras.applications.resnet50.preprocess_input\n",
    "\n",
    "train_ds_final = train_ds_augmented.map(lambda x, y: (preprocess_input_resnet50(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds_final = val_ds.map(lambda x, y: (preprocess_input_resnet50(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds_final = test_ds.map(lambda x, y: (preprocess_input_resnet50(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "print(\"✅ Datasets for transfer learning are ready.\")"
   ],
   "id": "4b94cdbd5cdab727"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_weights_from_dir(directory):\n",
    "    \"\"\"\n",
    "    Calculates class weights by counting files in subdirectories.\n",
    "    This is much faster than iterating through a tf.data.Dataset.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The path to the directory containing class subfolders\n",
    "                         (e.g., your TRAIN_DIR).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping class index to its calculated weight.\n",
    "    \"\"\"\n",
    "    print(f\"Calculating class weights from directory: {directory}\")\n",
    "\n",
    "    # Get class names from subfolder names, sorted alphabetically\n",
    "    # This ensures consistent ordering with what image_dataset_from_directory does\n",
    "    class_names = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))])\n",
    "\n",
    "    num_classes = len(class_names)\n",
    "    class_counts = []\n",
    "\n",
    "    # Count files in each class subfolder\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        count = len(os.listdir(class_path))\n",
    "        class_counts.append(count)\n",
    "        print(f\"- Found {count} images for class '{class_name}'\")\n",
    "\n",
    "    class_counts = np.array(class_counts)\n",
    "    total_samples = np.sum(class_counts)\n",
    "\n",
    "    # Calculate weights using the 'balanced' formula:\n",
    "    # weight = total_samples / (num_classes * count_for_that_class)\n",
    "    class_weights_array = total_samples / (num_classes * class_counts)\n",
    "\n",
    "    # Create the dictionary mapping class index to weight\n",
    "    class_weights_dict = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "\n",
    "    print(\"\\nCalculated Class Weights:\", class_weights_dict)\n",
    "    return class_weights_dict"
   ],
   "id": "b540fa6eeab1157a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class_weights = calculate_weights_from_dir(train_dir)\n",
    "\n",
    "print(class_weights)"
   ],
   "id": "5c83bb3097c33998"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_models(history, model):\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    best_model = tf.keras.models.load_model(model)\n",
    "    # Evaluation\n",
    "    print(\"\\nEvaluating model performance on the train set...\\n\")\n",
    "    results = best_model.evaluate(train_ds_final, verbose=1)\n",
    "\n",
    "    train_loss = results[0]\n",
    "    train_accuracy = results[1]\n",
    "\n",
    "    print(f\"Final Train Loss: {train_loss:.4f}\\n\")\n",
    "    print(f\"Final Train Accuracy: {train_accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "    print(\"\\nEvaluating model performance on the val set...\\n\")\n",
    "    results = best_model.evaluate(val_ds_final, verbose=1)\n",
    "\n",
    "    val_loss = results[0]\n",
    "    val_accuracy = results[1]\n",
    "\n",
    "    print(f\"Final Val Loss: {val_loss:.4f}\\n\")\n",
    "    print(f\"Final Val Accuracy: {val_accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "    print(\"\\nEvaluating model performance on the test set...\\n\")\n",
    "    results = best_model.evaluate(test_ds_final, verbose=1)\n",
    "\n",
    "    test_loss = results[0]\n",
    "    test_accuracy = results[1]\n",
    "\n",
    "    print(f\"Final Test Loss: {test_loss:.4f}\\n\")\n",
    "    print(f\"Final Test Accuracy: {test_accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "    y_pred_probs  = best_model.predict(test_ds_final)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    y_true = []\n",
    "    for images, labels in test_ds_final:\n",
    "      y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
    "\n",
    "      image_classes = train_ds.class_names\n",
    "\n",
    "    # Confusion matrix visualization\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=image_classes, yticklabels=image_classes)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n\\nClassification Report:\\n{classification_report(y_true, y_pred, target_names=image_classes)}\")"
   ],
   "id": "bf0c656f42bab517"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_classes = 7\n",
    "input_shape = (transfer_img_height, transfer_img_width, 3)\n",
    "\n",
    "batch = 32\n",
    "epochs = 30\n",
    "optimizer = AdamW(learning_rate=0.001, weight_decay=0.0001)"
   ],
   "id": "62498422b6fe9e22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_transfer_model(input_shape, num_classes):\n",
    "  base_model = tf.keras.applications.ResNet50(\n",
    "      include_top = False,\n",
    "      weights = 'imagenet',\n",
    "      input_shape = input_shape\n",
    "  )\n",
    "\n",
    "  base_model.trainable = False\n",
    "\n",
    "  model = Sequential([\n",
    "      base_model,\n",
    "      GlobalAveragePooling2D(),\n",
    "      Dense(256, activation='relu'),\n",
    "      Dropout(0.5),\n",
    "      Dense(num_classes, activation='softmax')\n",
    "  ], name=\"ResNet50_Transfer_Model\")\n",
    "\n",
    "  return model"
   ],
   "id": "9c13da7f8aa25b78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "transfer_model = build_transfer_model(input_shape=input_shape, num_classes=num_classes)",
   "id": "3900ca86bcff6867"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "save_model = ModelCheckpoint('/resnet_model_data_aug.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=2)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy',  patience=10,  restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "transfer_model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "history = transfer_model.fit(train_ds_final, epochs=epochs, validation_data=val_ds_final,\n",
    "                    callbacks=[save_model, early_stop, lr_scheduler], class_weight=class_weights, verbose=1)\n",
    "\n",
    "evaluate_models(history, model='resnet_model_data_aug.keras')"
   ],
   "id": "4da7a8f2ba8a350"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base_model = transfer_model.layers[0]\n",
    "base_model.trainable = True\n",
    "\n",
    "fine_tune_at = -20\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False\n",
    "\n",
    "optimizer_finetune = AdamW(learning_rate=1e-5, weight_decay=0.0001)\n",
    "fine_tune_epochs = 20\n",
    "total_epochs = epochs + fine_tune_epochs\n",
    "\n",
    "transfer_model.compile(\n",
    "    optimizer = optimizer_finetune,\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "transfer_model.summary()"
   ],
   "id": "2ff6f731a7fce366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "save_model_finetune = ModelCheckpoint('/finetuned_resnet_model_data_aug.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "history_finetune = transfer_model.fit(\n",
    "    train_ds_final, epochs=total_epochs, initial_epoch=history.epoch[-1],\n",
    "    validation_data=val_ds_final, callbacks=[save_model_finetune, early_stop, lr_scheduler],\n",
    "    class_weight=class_weights)\n",
    "\n",
    "evaluate_models(history_finetune, model='finetuned_resnet_model_data_aug.keras')"
   ],
   "id": "c993e1227d15d2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
