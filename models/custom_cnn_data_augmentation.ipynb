{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# IMPORT LIBRARIES\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import Input, RandomFlip, RandomRotation, RandomZoom\n",
    "\n",
    "from src.config import image_classes\n",
    "\n",
    "print(\"âœ… Libraries installed and imported.\")"
   ],
   "id": "ba1c0567a64f4533"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = np.load('/emotion_detection_data.npz')\n",
    "\n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "x_val = data['x_val']\n",
    "y_val = data['y_val']\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test']"
   ],
   "id": "ee9aeb3c60038477"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluation_function(history, model):\n",
    "    \"\"\"\n",
    "    Evaluates a trained Keras model by plotting training history, calculating\n",
    "    accuracy on train, validation, and test sets, and visualizing the confusion matrix.\n",
    "\n",
    "    This function expects `x_test`, `y_test`, `x_train`, `y_train`, `x_val`,\n",
    "    `y_val`, and `image_classes` to be globally accessible or passed implicitly\n",
    "    from the surrounding scope.\n",
    "\n",
    "    Args:\n",
    "        history (keras.callbacks.History): A History object returned by the `fit`\n",
    "            method of a Keras model. It contains the loss and metrics values\n",
    "            during training.\n",
    "        model (keras.Model or str): The Keras model object itself, or the path\n",
    "            to the saved weights file of the best performing model. The function\n",
    "            will load weights into `history.model` if `model` is a path.\n",
    "\n",
    "    Plots:\n",
    "        - **Model Loss:** A plot showing training loss and validation loss over epochs.\n",
    "        - **Model Accuracy:** A plot showing training accuracy and validation accuracy over epochs.\n",
    "        - **Confusion Matrix:** A heatmap visualizing the confusion matrix for\n",
    "          predictions on the test set.\n",
    "\n",
    "    Prints:\n",
    "        - The test accuracy of the submitted model.\n",
    "        - The train accuracy of the submitted model.\n",
    "        - The validation accuracy of the submitted model.\n",
    "    \"\"\"\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    history.model.load_weights(model)\n",
    "    test_acc = np.mean(np.argmax(history.model.predict(x_test),1)==np.argmax(y_test,1))\n",
    "    print('The submitted model has test accuracy equal to {}'.format(test_acc))\n",
    "\n",
    "    train_acc = np.mean(np.argmax(history.model.predict(x_train),1)==np.argmax(y_train,1))\n",
    "    print('The submitted model has train accuracy equal to {}'.format(train_acc))\n",
    "\n",
    "    val_acc = np.mean(np.argmax(history.model.predict(x_val),1)==np.argmax(y_val,1))\n",
    "    print('The submitted model has validation accuracy equal to {}'.format(val_acc))\n",
    "\n",
    "    y_pred_probs = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Confusion matrix visualization\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=image_classes, yticklabels=image_classes)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()"
   ],
   "id": "3d698fd1545e35f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "classes = 7\n",
    "batch = 16\n",
    "epochs = 60\n",
    "optimizer = AdamW(learning_rate=0.0001, weight_decay=0.0001)\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train.argmax(axis=1)), y=y_train.argmax(axis=1))\n",
    "class_weights = dict(enumerate(class_weights))"
   ],
   "id": "7e36099b4dcd219f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_augmentation = Sequential([\n",
    "    Input(shape=(48,48,1)),\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.05),\n",
    "    RandomZoom(0.1)\n",
    "], name=\"data_augmentation_pipeline\")"
   ],
   "id": "25eb82c573e7d661"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = Sequential([\n",
    "    data_augmentation,\n",
    "\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D((2,2), strides=(2,2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D((2,2), strides=(2,2)),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D((2,2), strides=(2,2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, (3,3), padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D((2,2), strides=(2,2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ],
   "id": "558fcb4060686269"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "save_model = ModelCheckpoint('custom_cnn_model_data_aug.keras', save_best_only=True, monitor='val_loss', mode='min', verbose=2)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy',  patience=10,  restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=0.0001, verbose=1)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    # train_generator,\n",
    "    batch_size=batch, epochs=epochs, validation_data=(x_val, y_val), shuffle = True, verbose=1,\n",
    "                    callbacks=[save_model, early_stop, lr_scheduler], class_weight = class_weights)\n",
    "\n",
    "evaluation_function(history, model='custom_cnn_model_data_aug.keras')"
   ],
   "id": "9ab682ed6ea774e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
